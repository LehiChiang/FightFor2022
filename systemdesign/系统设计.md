## Spring原理

Spring是一个轻量级Java开发框架，为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。Spring是一个全面的、企业应用开发一站式的解决方案，贯穿表现层、业务层、持久层。但是它仍然可以和其他的框架无缝整合。

## Spring特点

**控制反转：** Spring通过控制反转（IOC）技术实现解耦。一个对象依赖的其他对象会通过被动的方式传递进来，而不需要对象自己创建或者查找依赖。

**面向切面：** 支持切面（AOP）编程，并且把应用业务逻辑和系统服务区分开。

**容器：** Spring包含并管理应用对象的配置和生命周期，在这个意义上它是一种容器。可以配置每个bean如何被创建、销毁，bean的作用范围是单例还是每次都生成一个新的实例，以及他们是如何相互关联。


## Spring用到了哪些设计模式？

Spring 框架中使用到了大量的设计模式，下面列举了比较有代表性的：

*   `代理模式`—在 AOP中被用的比较多。

*   `单例模式`—在 spring 配置文件中定义的 bean 默认为单例模式。

*   `工厂模式`—BeanFactory 用来创建对象的实例


## Spring核心组件

<img src="https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0gzlqhXoYGN7kvLWLI4B0CpvtLZE9cok7EePH6S4L7B4WusQVqp8c5g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 33%;" />

*   `spring core`：提供了框架的基本组成部分，包括控制反转（Inversion of Control，IOC）和依赖注入（Dependency Injection，DI）功能。

*   `spring beans`：提供了BeanFactory，是工厂模式的一个经典实现，Spring将管理对象称为Bean。关注Java项目分享

*   `spring context`：构建于 core 封装包基础上的 context 封装包，提供了一种框架式的对象访问方法。

*   `spring jdbc`：提供了一个JDBC的抽象层，消除了烦琐的JDBC编码和数据库厂商特有的错误代码解析， 用于简化JDBC。

*   `spring aop`：提供了面向切面的编程实现，让你可以自定义拦截器、切点等。

*   `spring Web`：提供了针对 Web 开发的集成特性，例如文件上传，利用 servlet listeners 进行 ioc 容器初始化和针对 Web 的 ApplicationContext。

*   `spring test`：主要为测试提供支持的，支持使用JUnit或TestNG对Spring组件进行单元测试和集成测试。


## 控制反转（IOC）

控制反转（IoC）是一个比较抽象的概念，是Spring框架的核心，用来消减计算机程序的耦合问题。依赖注入（DI）是IoC的另外一种说法，只是从不同的角度，描述相同的概念。

当Spring框架出现之后，对象的实例化不再由调用者来创建，而是由Spring容器来创建。Spring容器会负责控制程序之间的关系，而不是由调用者的程序代码直接控制。这样，控制权由调用者转移到Spring容器，控制权发生了反转，这就是Spring的控制反转。

从spring容器角度来看，spring容器负责将被依赖对象复制给调用者的成员变量，相当于为调用者注入它所依赖的实例，这就是spring的依赖注入，主要目的是为了解耦，体现一种“组合”的理念。

综上所述，控制反转是一种通过描述文件（XML或者注解）并通过第三方产生或获取特定对象的方法，在spring中实现控制反转的是IOC容器，其实现方法是依赖注入。

## IOC 容器实现

BeanFactory 是 Spring 框架的基础设施，面向 Spring 本身；

ApplicationContext 面向使用Spring 框架的开发者，几乎所有的应用场合我们都直接使用 ApplicationContext 而非底层的 BeanFactory。



## ApplicationContext 面向开发应用

ApplicationContext 由 BeanFactory 派生而来，提供了更多面向实际应用的功能。

ApplicationContext 继承了 HierarchicalBeanFactory 和 ListableBeanFactory 接口，在此基础上，还通过多个其他的接口扩展了 BeanFactory 的功能：



## BeanFactory 和 ApplicationContext有什么区别？

BeanFactory和ApplicationContext是Spring的两大核心接口，都可以当做Spring的容器。其中ApplicationContext是BeanFactory的子接口。

### 依赖关系

BeanFactory：是Spring里面最底层的接口，包含了各种Bean的定义，读取bean配置文档，管理bean的加载、实例化，控制bean的生命周期，维护bean之间的依赖关系。

ApplicationContext：接口作为BeanFactory的派生，除了提供BeanFactory所具有的功能外，还提供了更完整的框架功能：

*   继承MessageSource，因此支持国际化。

*   统一的资源文件访问方式。

*   提供在监听器中注册bean的事件。

*   同时加载多个配置文件。

*   载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层。


### 加载方式

BeanFactroy：采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调getBean())，才对该Bean进行加载实例化。这样，我们就不能发现一些存在的Spring的配置问题。如果Bean的某一个属性没有注入，BeanFacotry加载后，直至第一次使用调用getBean方法才会抛出异常。

ApplicationContext：它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误，这样有利于检查所依赖属性是否注入。ApplicationContext启动后预载入所有的单实例Bean，通过预载入单实例bean ,确保当你需要的时候，你就不用等待，因为它们已经创建好了。

相对于基本的BeanFactory，ApplicationContext 唯一的不足是占用内存空间。当应用程序配置Bean较多时，程序启动较慢。

### 创建方式

BeanFactory通常以编程的方式被创建，ApplicationContext还能以声明的方式创建，如使用ContextLoader。

### 注册方式

BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册。

### ApplicationContext通常的实现

*   FileSystemXmlApplicationContext ：此容器从一个XML文件中加载beans的定义，XML Bean 配置文件的全路径名必须提供给它的构造函数。

*   ClassPathXmlApplicationContext：此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置。

*   WebXmlApplicationContext：此容器加载一个XML文件，此文件定义了一个WEB应用的所有bean。


## Spring Bean 作用域

Spring 3 中为 Bean 定义了 5 中作用域，分别为 singleton（单例）、prototype（原型）、request、session 和 global session，5 种作用域说明如下：

*   **singleton**：单例模式（多线程下不安全）。Spring IoC 容器中只会存在一个共享的 Bean 实例，无论有多少个Bean 引用它，始终指向同一对象。该模式在多线程下是不安全的。Singleton 作用域是Spring 中的缺省作用域，也可以显示的将 Bean 定义为 singleton 模式，配置为：

*   **prototype**:原型模式每次使用时创建。每次通过 Spring 容器获取 prototype 定义的 bean 时，容器都将创建一个新的 Bean 实例，每个 Bean 实例都有自己的属性和状态，而 singleton 全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton 作用域。

*   **Request**：一次 request 一个实例。在一次 Http 请求中，容器会返回该 Bean 的同一实例。而对不同的 Http 请求则会产生新的 Bean，而且该 bean 仅在当前 Http Request 内有效,当前 Http 请求结束，该 bean实例也将会被销毁。

*   **session**：在一次 Http Session 中，容器会返回该 Bean 的同一实例。而对不同的 Session 请求则会创建新的实例，该 bean 实例仅在当前 Session 内有效。同 Http 请求相同，每一次session 请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的 session 请求内有效，请求结束，则实例将被销毁。

*   **global Session**：在一个全局的 Http Session 中，容器会返回该 Bean 的同一个实例，仅在使用 portlet context 时有效。

## AOP原理

OOP(Object-Oriented Programming)面向对象编程，允许开发者定义纵向的关系，但并适用于定义横向的关系，导致了大量代码的重复，而不利于各个模块的重用。

AOP(Aspect-Oriented Programming)，一般称为面向切面编程，作为面向对象的一种补充，用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，这个模块被命名为“切面”（Aspect），减少系统中的重复代码，降低了模块间的耦合度，同时提高了系统的可维护性。

AOP 主要应用场景有

*   Authentication 权限
*   Error handling 错误处理
*   Persistence 持久化
*   Synchronization 同步
*   Transactions 事务


## AOP 核心概念

*   切面（aspect）：类是对物体特征的抽象，切面就是对横切关注点的抽象

*   横切关注点：对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点

*   连接点（joinpoint）：被拦截到的点，因为 Spring 只支持方法类型的连接点，所以在 Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器

*   切入点（pointcut）：对连接点进行拦截的定义

*   通知（advice）：所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类

*   目标对象：代理的目标对象

*   织入（weave）：将切面应用到目标对象并导致代理对象创建的过程


*   编译期：切面在目标类编译时被织入。AspectJ的织入编译器是以这种方式织入切面的；

*   类加载期：切面在目标类加载到JVM时被织入。需要特殊的类加载器，它可以在目标类被引入应用之前增强该目标类的字节码。AspectJ5的加载时织入就支持以这种方式织入切面；

*   运行期：切面在应用运行的某个时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象动态地创建一个代理对象。SpringAOP就是以这种方式织入切面。


*   引入（introduction）：在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段

## AOP 实现方式

AOP实现的关键在于代理模式，AOP代理主要分为静态代理和动态代理。

*   AspectJ 静态代理的增强，所谓静态代理，就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强，他会在编译阶段将AspectJ(切面)织入到Java字节码中，运行的时候就是增强之后的AOP对象。

*   Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是每次运行时在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。


## AOP 两种代理方式

Spring 提供了两种方式来生成代理对象: JDK Proxy 和 Cglib，具体使用哪种方式生成由AopProxyFactory 根据 AdvisedSupport 对象的配置来决定。默认的策略是如果目标类是接口，则使用 JDK 动态代理技术，否则使用 Cglib 来生成代理。

## JDK 动态接口代理

JDK 动态代理主要涉及到 java.lang.reflect 包中的两个类：Proxy 和 InvocationHandler。

InvocationHandler是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编制在一起。

Proxy 利用 InvocationHandler 动态创建一个符合某一接口的实例，生成目标类的代理对象。

## Spring MVC 原理

Spring 的模型-视图-控制器（MVC）框架是围绕一个 DispatcherServlet 来设计的，这个 Servlet会把请求分发给各个处理器，并支持可配置的处理器映射、视图渲染、本地化、时区与主题渲染等，甚至还能支持文件上传。

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0mdRvhAbtrBTz9qp4vbE0AZ40sYukU75NJjJPicfp4EicAu1ibSsgAy95g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**Http 请求到 DispatcherServlet**

(1) 客户端请求提交到 DispatcherServlet。

**HandlerMapping 寻找处理器**

(2) 由 DispatcherServlet 控制器查询一个或多个 HandlerMapping，找到处理请求的Controller。

**调用处理器 Controller**

(3) DispatcherServlet 将请求提交到 Controller。

**Controller 调用业务逻辑处理后，返回 ModelAndView**

(4)(5)调用业务处理和返回结果：Controller 调用业务逻辑处理后，返回 ModelAndView。

**DispatcherServlet 查询 ModelAndView**

(6)(7)处理视图映射并返回模型：DispatcherServlet 查询一个或多个 ViewResoler 视图解析器，找到 ModelAndView 指定的视图。

**ModelAndView 反馈浏览器 HTTP**

(8) Http 响应：视图负责将结果显示到客户端。

## Spring常用注解

### 声明bean的注解

*   `@Component` ：组件，没有明确的角色

*   `@Service` ：在业务逻辑层使用

*   `@Repository` ：在数据访问层使用

*   `@Controller` ：在展现层使用，控制层的声明

*   `@RestController` ：`@Controller`和`@ResponseBody`组合，用于返回JSON格式数据


### 注入bean的注解

*   `@Autowired`：

该注解可以对类成员变量，方法，及构造方法，进行标注，完成动装配的工作。通过`@Autowired`的使用来消除`setter`和`getter`的方法，默认按照`Bean`的`类型`进行装配。

*   `@Inject`：


JSR330 (Dependency Injection for Java)中的规范，需要导入javax.inject.Inject jar包 ，才能实现注入 作用CONSTRUCTOR、METHOD、FIELD上

根据类型进行自动装配的，如果需要按名称进行装配，则需要配合@Named

*   `@Resource`：

该注解与`@Autowired`的功能一样，区别在于，该注解默认是按照名称来装配注入的，只有当找不到与名称匹配的`Bean`时，才会按照类型来装配注入；而`@Autowired`默认按照`Bean`
的类型进行装配，如果想按照名称来装配注入，而需要结合`@Qualifier`注解一起使用。

`@Resource`注解有两个属性：`name`和`type`。`name`属性是指定`Bean`实例名称，即按照名称来装配注入；`type`属性指定`Bean`类型，即按照`Bean`
的类型进行装配。如`@Resource("testDAO")`，名称就是`testDAO`。

- @Qualifier

该注解与`@Autowired`的注解配合使用，当`@Autowired`的注解需要按照名称来装配注入时，需要结合该注解一起使用，Bean的实例名称，由@Qualifier注解的参数指定。

### 配置类相关注解

*   `@Configuration` ：声明当前类为配置类，相当于xml形式的Spring配置（类上），声明当前类为配置类，其中内部组合了@Component注解，表明这个类是一个bean（类上）

*   `@Bean` ：注解在方法上，声明当前方法的返回值为一个bean，替代xml中的方式（方法上）

*   `@ComponentScan` ：用于对Component进行扫描，相当于xml中的（类上）



### AOP相关注解

Spring支持AspectJ的注解式切面编程

*   `@Aspect`：声明一个切面（类上），使用@After、@Before、@Around定义建言（advice），可直接将拦截规则（切点）作为参数。

*   `@After` ：在方法执行之后执行（方法上）

*   `@Before` ：在方法执行之前执行（方法上）

*   `@Around` ：在方法执行之前与之后执行（方法上）

*   `@PointCut` ：声明切点在java配置类中使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持（类上）



### SpringMVC注解

*   `@RequestMapping` ：用于映射Web请求，包括访问路径和参数（类或方法上）

*   `@ResponseBody` ：支持将返回值放在response内，而不是一个页面，通常用户返回json数据（返回值旁或方法上）

*   `@RequestBody` ：允许request的参数在request体中，而不是在直接连接在地址后面。（放在参数前）

*   `@PathVariable` ：用于接收路径参数，比如@RequestMapping(“/hello/{name}”)申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。

*   `@RestController` ：该注解为一个组合注解，相当于@Controller和@ResponseBody的组合，注解在类上，意味着，该Controller的所有方法都默认加上了@ResponseBody。

*   `@ControllerAdvice` ：通过该注解，我们可以将对于控制器的全局配置放置在同一个位置，注解了@Controller的类的方法可使用@ExceptionHandler、@InitBinder、@ModelAttribute注解到方法上，这对所有注解了 @RequestMapping的控制器内的方法有效。

*   `@ExceptionHandler` ：用于全局处理控制器里的异常

*   `@ModelAttribute` ：本来的作用是绑定键值对到Model里，在@ControllerAdvice中是让全局的@RequestMapping：都能获得在此处设置的键值对。



## @Bean的属性支持

@Scope 设置Spring容器如何新建Bean实例（方法上，得有@Bean），其设置类型包括：

*   `Singleton`：单例,一个Spring容器中只有一个bean实例，默认模式

*   `Protetype`：每次调用新建一个bean

*   `Request`：web项目中，给每个http request新建一个bean

*   `Session` ：web项目中，给每个http session新建一个bean

*   `Global`：Session给每一个 global http session新建一个Bean实例

*   `@StepScope`：在Spring Batch中还有涉及(Spring Batch 之 背景框架简介\_vincent-CSDN博客)

*   `@PostConstruct` ：由JSR-250提供，在构造函数执行完之后执行，等价于xml配置文件中bean的initMethod

*   `@PreDestory` ：由JSR-250提供，在Bean销毁之前执行，等价于xml配置文件中bean的destroyMethod


## @Value注解

为属性注入值,支持如下方式的注入：

注入普通字符

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0TGXBNM94XZrbaQswhsD4gpZtHkSz7J3cDUXRHkmm7uWXJCVlt2xiafw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注入操作系统属性

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0vgNFBShprngOeIOGRzAwB9c0yabT5ANH8vemFZrtPxSzJVL0Ox5qoQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注入表达式结果

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs00kfjJT0DaibiatmySaRu9XstMSSnMs9BMRzj1gA8nX0t8q9SpAtnA6Gg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注入其它bean属性

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0wRawW1KEduGGdTL5CcrjtcOUurRQmRPAUwCLNE5D75WEmgOViacneEw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注入文件资源

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0KvjXt7iaxpwaEF3eYSq9SCp8quzYBWibb3uOVwwI5gnEyl1VZ1ia4w1mA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注入网站资源

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0O9W5icQUjVKtARtl0Easy7pAHbnib07bfSncdicdMUne92KNJotQ58qOA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注入配置文件

![图片](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbud8CU3hg3Mg9dvdxcasogs0d8icjekqCaN1KSDJ3gibibjoU97naELI2PicicydsDZ4wkMg6Xj8j5kUZxw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`@PropertySource` 加载配置文件(类上)，还需配置一个`PropertySourcesPlaceholderConfigurer`的bean。



## 10亿int整型数，统计只出现一次的数

https://blog.csdn.net/qq_35290785/article/details/98672144



## 亿级用户游戏排行榜设计方案

https://blog.csdn.net/riemann_/article/details/113828075



## 加密算法分类

对称加密：AES，DES

非对称加密：RSA，DSA(Digital Signature Algorithm，数字签名)， ECC(Elliptic Curves Cryptography，椭圆曲线密码编码学)

消息摘要算法：MD2，4，5(信息摘要算法)，SHA(安全散列算法)，HMAC(散列消息鉴别码)



## 网站是怎样解决多用户高并发访问的

为了解决大型网站的访问量大、并发量高、海量数据的问题，我们一般会考虑业务拆分和分布式部署。分布式是指将不同的业务分布在不同的地方；而集群指的是将几台服务器集中在一起，实现同一业务。分布式中的每一个节点，都可以做集群。 而集群并不一定就是分布式的。分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。

我们可以把那些关联不太大的业务独立出来，部署到不同的机器上，从而实现大规模的分布式系统。但这之中也有一个问题，那就是用户如何选择相应的机器的问题，这也被称为访问统一入口问题，而解决的方法是我们可以在集群机器的前面增加负载均衡设备，实现流量分发（总图如下）。

负载均衡就是将负载（工作任务、访问请求等）进行平衡、分摊到多个操作单元（服务器、组件等）上进行执行，是解决高性能，单点故障（高可用，如果你是单机版网络，一旦服务器挂掉了，那么用户就无法请求了，但对于集群来说，一台服务器挂掉了，负载均衡器会把用户的请求发送给其他的服务器进行处理），扩展性（这里主要是指水平伸缩）的终极解决方案。

最好配上数据库的主从部署，因为如果在集群中只分配一个数据库服务器，那么这个系统的瓶颈将会出现在数据库的操作上，虽然redis能减轻这种负担，但对于数据量大的还是有一定影响的，而且数据库的主从部署也可以防止因某个数据库服务器的挂掉而丢失用户的信息。



## 数据库集群

数据库集群，顾名思义，就是利用至少两台或者多台数据库服务器，构成一个虚拟单一数据库逻辑映像，像单数据库系统那样，向客户端提供透明的数据服务。

> 与分布式数据库系统的区别

- 数据库集群有的具有单份数据集，有的具有两份或多份相似的数据集，有的具有两份或多份实时一致的数据集；而分布式数据库系统往往具有完全不同的数据集。
- 数据库集群往往是同构的系统，要求集群各节点都具有相同的操作系统和数据库系统版本，甚至补丁包的版本也要求保持一致；而分布式数据库系统可以是异构系统，包含不同的操作系统和不同的数据库系统。
- 数据库集群往往建立在高速局域网内；而分布式数据库系统既可以是高速局域网，也可以是跨部门、跨单位的异地远程网络。

> **为什么要用数据库集群**

- 通过使用数据库集群可以使读写分离，提高数据库的系统性能。

  mysql是支持分布式的。MySQL Proxy最强大的一项功能是实现“读写分离(Read/Write Splitting)”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库，从而使从数据库和主数据库的数据保持一致。 当然，主服务器也可以提供查询服务。使用读写分离最大的作用无非是环境服务器压力。



## 分布式架构和单体应用的优缺点

使用分布式系统主要有两方面原因。

- 增大系统容量. 我们的业务量越来越大，而要能应对越来越大的业务量，一台机器的性能已经无法满足了，我们需要多台机器才能应对大规模的应用场景。所以，我们需要垂直或是水平拆分业务系统，让其变成一个分布式的架构。
- 加强系统可用。我们的业务越来越关键，需要提高整个系统架构的可用性，这就意味着架构中不能存在单点故障。这样，整个系统不会因为一台机器出故障而导致整体不可用。所以，需要通过分布式架构来冗余系统以消除单点故障，从而提高系统的可用性。
  分布式架构和单体应用的优缺点对比

<img src="https://img-blog.csdnimg.cn/20200530162409967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW94dWFueA==,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 50%;" />

从上面的表格我们可以看到，分布式系统虽然有一些优势，但也存在一些问题。

- 架构设计变得复杂（尤其是其中的分布式事务）
- 部署单个服务会比较快，但是如果一次部署需要多个服务，流程会变得复杂。
- 系统的吞吐量会变大，但是响应时间会变长。
- 运维复杂度会因为服务变多而变得很复杂。
- 架构复杂导致学习曲线变大。
- 测试和查错的复杂度增大。
- 技术多元化，这会带来维护和运维的复杂度。
- 管理分布式系统中的服务和调度变得困难和复杂。



## 分布式CAP

**CAP理论**

- **C ，单词Consistency，一致性**：

  > All nodes see the same data at the same time

  所有数据库集群节点在同一时间点看到的数据完全一致，即所有节点能实时保持数据同步。

- **A，单词Availability**， **可用性**：分布式系统一直处于可用状态，对于请求总是能在有限的时间内返回结果。

  > Reads and writes always succeed

  读写操作永远是成功的。即服务一直是可用的，即使集群一部分节点故障，集群整体还能正常响应客户端的读写请求。

- **P ，单词 Partition tolerance，分区容错性**：尽管系统中有任意的信息丢失或故障，仍能对外提供满足一致性和可用性的服务。

  > The system continues to operate despite arbitrary message loss or failure of part of the system



***CAP理论，一个分布式系统不可能同时满足一致性、可用性和分区容错性这三个基本要求，最多同时满足其中的两项***。

**CAP权衡使用**

1、保留CA，放弃P

如果想避免分区容错性问题的发生，一种做法是将所有的数据（与事务相关的）都放在一台机器上。虽然无法100%保证系统不会出错，但不会碰到由分区带来的负面效果。当然这个选择会严重的影响系统的扩展性。

作为一个分布式系统，放弃P，即相当于放弃了分布式，一旦并发性很高，单机服务根本不能承受压力。

像很多银行服务，确确实实就是舍弃了P，只用单台小型机+ORACLE保证服务可用性。

2、保留CP，放弃A

相对于放弃“分区容错性“来说，其反面就是放弃可用性。一旦遇到分区容错故障，那么受到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供服务。

作为分布式系统，有分区服务发生问题很有可能，如果因为某些服务不能用，导致整个服务都不能用，这个根本不是好的分布式系统。

3、保留AP，舍弃C

这里所说的放弃一致性，并不是完全放弃数据一致性，而是放弃数据的强一致性。即放弃了同一时刻的数据一致性，而保留数据的最终一致性。

以网络购物为例，对只剩下一件库存的商品，如果同时接受到了两份订单，那么较晚的订单将被告知商品告罄。

通常情况下，很多分布式服务系统都是采用该方案，保证可用性性，分布式服务，因为某些分区服务发生问题，先容忍，最终通过一些折中的方法达到最终数据一致性。



## 分布式事务

分布式事务指事务的操作位于不同的节点上，需要保证事务的 AICD 特性。例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。

### 一、两阶段提交（2PC）

两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。

1.1 准备阶段

协调者询问参与者事务是否执行成功，参与者发回事务执行结果。

![img](https://oscimg.oschina.net/oscnet/62cf113cd8c40eaafecb9fc6111beef4480.jpg)

1.2 提交阶段

如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

![img](https://oscimg.oschina.net/oscnet/6610fc7d97c9277423a9c620487e09db3f8.jpg)

2. 存在的问题

- 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。

- 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。

- 数据不一致 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。



### 二、三阶段提交（3PC）

三段提交（`3PC`）是二阶段提交（`2PC`）的一种改进版本 ，为解决两阶段提交协议的阻塞问题，上边提到两段提交，当协调者崩溃时，参与者不能做出最后的选择，就会一直保持阻塞锁定资源。

`2PC` 中只有协调者有超时机制，`3PC` 在协调者和参与者中都引入了超时机制，协调者出现故障后，参与者就不会一直阻塞。而且在第一阶段和第二阶段中又插入了一个准备阶段（如下图，看着有点啰嗦），保证了在最后提交阶段之前各参与节点的状态是一致的。

![img](https://img-blog.csdnimg.cn/20201119154252414.png?#pic_center)

虽然 `3PC` 用超时机制，解决了协调者故障后参与者的阻塞问题，但与此同时却多了一次网络通信，性能上反而变得更差，也不太推荐。



### 三、TCC

所谓的 `TCC` 编程模式，也是两阶段提交的一个变种，不同的是 `TCC` 为在业务层编写代码实现的两阶段提交。`TCC` 分别指 `Try`、`Confirm`、`Cancel` ，一个业务操作要对应的写这三个方法。

- Try 阶段主要是对业务系统做检测及资源预留
- Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。
- Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。

以下单扣库存为例，`Try` 阶段去占库存，`Confirm` 阶段则实际扣库存，如果库存扣减失败 `Cancel` 阶段进行回滚，释放库存。

TCC 不存在资源阻塞的问题，因为每个方法都直接进行事务的提交，一旦出现异常通过则 `Cancel` 来进行回滚补偿，这也就是常说的补偿性事务。

原本一个方法，现在却需要三个方法来支持，可以看到 TCC 对业务的侵入性很强，而且这种模式并不能很好地被复用，会导致开发量激增。还要考虑到网络波动等原因，为保证请求一定送达都会有重试机制，所以考虑到接口的幂等性。



### 四、本地消息表

本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。

1. 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。
2. 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。
3. 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。

<img src="https://oscimg.oschina.net/oscnet/915a02484990dda820410c8cad2389c5386.jpg" alt="img" style="zoom:67%;" />

优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。

缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。



## 负载均衡算法

集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。

负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。

负载均衡器可以用来实现高可用以及伸缩性：

- 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
- 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。

负载均衡器运行过程包含两个部分：

1. 根据负载均衡算法得到转发的节点；
2. 进行转发。



### 1. 轮询（Round Robin）

轮询算法把每个请求轮流发送到每个服务器上。

下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/9daa3616-00a4-48c4-9146-792dc8499be3.jpg" alt="img" style="zoom:50%;" />



该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/bfea8772-d01b-4a51-8adc-edfd7d3dce84.jpg" alt="img" style="zoom:50%;" />



### 2. 加权轮询（Weighted Round Robbin）

加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。

例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/4ab87717-e264-4232-825d-8aaf08f14e8b.jpg" alt="img" style="zoom:50%;" />



### 3. 最少连接（least Connections）

由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开，此时 (6, 4) 请求连接服务器 2。该系统继续运行时，服务器 2 会承担过大的负载。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e98deb5a-d5d4-4294-aa9b-9220d4483403.jpg" alt="img" style="zoom:50%;" />



最少连接算法就是将请求发送给当前最少连接数的服务器上。

例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/43d323ac-9f07-4e4a-a315-4eaf8c38766c.jpg" alt="img" style="zoom:50%;" />



### 4. 加权最少连接（Weighted Least Connection）

在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。

### 5. 随机算法（Random）

把请求随机发送到服务器上。

和轮询算法类似，该算法比较适合服务器性能差不多的场景。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a42ad3a7-3574-4c48-a783-ed3d08a0688a.jpg" alt="img" style="zoom:50%;" />



### 6. 源地址哈希法 (IP Hash)

源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。

可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/0f399a9f-1351-4b2d-b8a4-2ebe82b1a703.jpg" alt="img" style="zoom:50%;" />

## 负载均衡的转发实现

### 1. HTTP 重定向

HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。

缺点：

- 需要两次请求，因此访问延迟比较高；
- HTTP 负载均衡器处理能力有限，会限制集群的规模。

该负载均衡转发的缺点比较明显，实际场景中很少使用它。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/02a1fbfd-7a9d-4114-95df-ca2445587a1f.jpg" alt="img" style="zoom: 67%;" />



### 2. DNS 域名解析

在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。

优点：

- DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。

缺点：

- 由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。

大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/d2c072cc-8b17-480c-813e-18cdb3b4b51f.jpg" alt="img" style="zoom:67%;" />



### 3. 反向代理服务器

反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。

在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。

优点：

- 与其它功能集成在一起，部署简单。

缺点：

- 所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。



## 集群下的 Session 管理

### Session Replication

在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。

缺点：

- 占用过多内存；
- 同步过程占用网络带宽以及服务器处理器时间。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/40c6570d-c1d7-4c38-843e-ba991b2328c2.png" alt="img" style="zoom: 50%;" />



### Session Server

使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。

优点：

- 为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。

缺点：

- 需要去实现存取 Session 的代码。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/fdc45a09-f838-4348-8959-d2c793727788.png" alt="img" style="zoom:50%;" />

## 缓存位置

### 浏览器

当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。

### ISP

网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。

###  反向代理

反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。

###  本地缓存

使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。

### 分布式缓存

使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。

相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。

### 数据库缓存

MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。

### Java 内部的缓存

Java 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。

### CPU 多级缓存

CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。



## CDN内容分发网络

内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。

CDN 主要有以下优点：

- 更快地将数据分发给用户；
- 通过部署多台服务器，从而提高系统整体的带宽性能；
- 多台服务器可以看成是一种冗余机制，从而具有高可用性。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/15313ed8-a520-4799-a300-2b6b36be314f.jpg)

## 什么是消息队列

你可以把消息队列理解为一个使用队列来通信的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：

我们通常说的消息队列，简称MQ（Message Queue），它其实就指消息中间件，当前业界比较流行的开源消息中间件包括：RabbitMQ、RocketMQ、Kafka。



## 为什么使用消息队列

### 应用解耦

- 场景

  - 举个常见业务场景：下单扣库存，用户下单后，订单系统去通知库存系统扣减。传统的做法就是订单系统直接调用库存系统：
  - 如果库存系统无法访问，下单就会失败，订单和库存系统存在耦合关系
  - 如果业务又接入一个营销积分服务，那订单下游系统要扩充，如果未来接入越来越多的下游系统，那订单系统代码需要经常修改
- 解决方案

### 流量削峰

- 场景

  - 我们做秒杀实现的时候，需要避免流量暴涨，打垮应用系统的风险。可以在应用前面加入消息队列。

- 解决方案

  - 假设秒杀系统每秒最多可以处理2k个请求，每秒却有5k的请求过来，可以引入消息队列，秒杀系统每秒从消息队列拉2k请求处理得了。
  - 不用担心积压问题，因为首先秒杀活动不会每时每刻都那么多请求过来，高峰期过去后，积压的请求可以慢慢处理；其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面；

### 异步处理

- 场景

  - 用户注册成功后，给它发个短信和发个邮件。
  - 如果注册信息入库是30ms，发短信、邮件也是30ms，三个动作串行执行的话，会比较耗时，响应90ms：

- 解决方案

  - 如果采用并行执行的方式，可以减少响应时间。注册信息入库后，同时异步发短信和邮件。如何实现异步呢，用消息队列即可，就是说，注册信息入库成功后，写入到消息队列（这个一般比较快，如只需要3ms），然后异步读取发邮件和短信。

### 消息通讯

- 场景

  - 如实现点对点消息队列、聊天室等。



## 消息队列如何解决消息丢失问题

### 生产者保证不丢消息

- 采用同步方式发送，send消息方法返回成功状态，就表示消息正常到达了存储端Broker。
- 如果send消息异常或者返回非成功状态，可以重试。
- 可以使用事务消息，RocketMQ的事务消息机制就是为了保证零丢失来设计的

### 存储端不丢消息

- 确保消息持久化到磁盘。大家很容易想到就是刷盘机制。

### 消费者不丢消息

- 消费者执行完业务逻辑，再反馈会Broker说消费成功，这样才可以保证消费阶段不丢消息。



## Redis的好处、特点

- 既可以做持久化存储，也可以当作缓存。
- 作为持久层，它存储的数据是半结构化的，这意味着计算机读入内存中有更少的规则，读入速度更快。对于结构化，多范式规则的数据库而言，它更具有优势。
- 作为缓存，它支持大数据存入内存中，只要命中率高，它就能快速响应。响应速度每秒可达到大约10万次的读写操作。
- 支持5种数据类型可以满足存储各种数据结构体的需要，另一方面数据类型少，使得规则少，判断的逻辑就少，这样读写速度就更快。
- 支持分布式锁，集群，主从复制等配置。还支持一定的事务能力，在高并发场景下保证数据安全和一致性。
- 数据的相关操作使用单线程的工作方式，并且使用I/O多路复用的方式进行通信



## Redis的应用

- 热点数据加速查询（主要场景），如热点商品、热点新闻、热点资讯、推广类等高访问量信息等
- 即时信息查询，如各位排行榜、各类网站访问统计等
- 时效性信息控制，如验证码控制等
- 分布式数据共享，如分布式集群架构中的 session 分离
- 任务队列，如秒杀、抢购、购票排队等
- 单服务器升级集群
- 消息队列
- 分布式锁



## 单机的Redis存在四大问题

<img src="D:\Java Programs\LeetcodeChallenge\systemdesign\redis\imgs\image-20210725144240631.png" alt="image-20210725144240631" style="zoom:67%;" />



## RDB原理

bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。

fork采用的是copy-on-write技术：

- 当主进程执行读操作时，访问共享内存；
- 当主进程执行写操作时，则会拷贝一份数据，执行写操作。

<img src="D:\Java Programs\LeetcodeChallenge\systemdesign\redis\imgs\image-20210725151319695.png" alt="image-20210725151319695" style="zoom:60%;" />



## master如何判断slave节点是不是第一次来做数据同步？

有几个概念，可以作为判断依据：

- **Replication Id**：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid
- **offset**：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。

因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。



因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。

master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。

master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。

因此，**master判断一个节点是否是第一次同步的依据，就是看replid是否一致**。



## 主从复制的作用

- 读写分离：master写、slave读，提高服务器的读写负载能力
- 负载均衡：基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量
- 故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复
- 数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式
- 高可用基石：基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案



## Redis的高可用指的是什么？

两个层面：

- 数据不能丢失，或者说尽量减少丢失，可以通过AOF和RDB保证。
- 保证Redis服务不中断，不能单点部署了，选择主从复制



## Redis实现分布式锁的四种方案

### 什么是分布式锁

> 分布式锁其实就是，控制分布式系统不同进程共同访问共享资源的一种锁的实现。如果不同的系统或同一个系统的不同主机之间共享了某个临界资源，往往需要互斥来防止彼此干扰，以保证一致性。

我们先来看下，一把靠谱的分布式锁应该有哪些特征：

- **「互斥性」**: 任意时刻，只有一个客户端能持有锁。
- **「锁超时释放」**：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。
- **「可重入性」**:一个线程如果获取了锁之后,可以再次对其请求加锁。
- **「高性能和高可用」**：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。
- **「安全性」**：锁只能被持有的客户端删除，不能被其他客户端删除



Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。



### 方案一：SETNX + EXPIRE

提到Redis的分布式锁，就会想到`setnx`+ `expire`命令。即先用`setnx`来抢锁，如果抢到之后，再用`expire`给锁设置一个过期时间，防止锁忘记了释放。

> SETNX 是SET IF NOT EXISTS的简写.日常命令格式是SETNX key value，如果 key不存在，则SETNX成功返回1，如果这个key已经存在了，则返回0。

假设某电商网站的某商品做秒杀活动，key可以设置为key_resource_id,value设置任意值，伪代码如下：

```java
if(jedis.setnx(key_resource_id,lock_value) == 1) { //加锁
    expire（key_resource_id，100）; //设置过期时间
    try {
        do something  //业务请求
    }catch(){
  }
  finally {
       jedis.del(key_resource_id); //释放锁
    }
}
```

但是这个方案中，`setnx`和`expire`两个命令分开了，**「不是原子操作」**。如果执行完`setnx`加锁，正要执行`expire`设置过期时间时，进程crash或者要重启维护了，那么这个锁就“长生不老”了，**「别的线程永远获取不到锁啦」**。

### 方案二：使用Lua脚本(包含SETNX + EXPIRE两条指令)

实际上，我们还可以使用Lua脚本来保证原子性（包含`setnx`和`expire`两条指令），lua脚本如下：

```java
if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then
   redis.call('expire',KEYS[1],ARGV[2])
else
   return 0
end;
```

加锁代码如下

```java
 String lua_scripts = "if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then" +
            " redis.call('expire',KEYS[1],ARGV[2]) return 1 else return 0 end";   
Object result = jedis.eval(lua_scripts, Collections.singletonList(key_resource_id), Collections.singletonList(values));
//判断是否成功
return result.equals(1L);
```

这个方案，跟方案二对比，你觉得哪个更好呢？

### 方案三：SET EX PX NX

除了使用，使用Lua脚本，保证`SETNX + EXPIRE`两条指令的原子性，我们还可以巧用Redis的SET指令扩展参数！（`SET key value[EX seconds][PX milliseconds][NX|XX]`），它也是原子性的！

> SET key value [EX seconds] [PX milliseconds] [NX|XX]
>
> - NX :表示key不存在的时候，才能set成功，也即保证只有第一个客户端请求才能获得锁，而其他客户端请求只能等其释放锁，才能获取。
> - EX seconds :设定key的过期时间，时间单位是秒。
> - PX milliseconds: 设定key的过期时间，单位为毫秒
> - XX: 仅当key存在时设置值

伪代码demo如下：

```java
if（jedis.set(key_resource_id, lock_value, "NX", "EX", 100s) == 1）{ //加锁
    try {
        do something  //业务处理
    }catch(){
  }
  finally {
       jedis.del(key_resource_id); //释放锁
    }
}
```

但是呢，这个方案还是可能存在问题

- 问题一：**「锁过期释放了，业务还没执行完」**。假设线程a获取锁成功，一直在执行临界区的代码。但是100s过去后，它还没执行完。但是，这时候锁已经过期了，此时线程b又请求过来。显然线程b就可以获得锁成功，也开始执行临界区的代码。那么问题就来了，临界区的业务代码都不是严格串行执行的啦。
- 问题二：**「锁被别的线程误删」**。假设线程a执行完后，去释放锁。但是它不知道当前的锁可能是线程b持有的（线程a去释放锁时，有可能过期时间已经到了，此时线程b进来占有了锁）。那线程a就把线程b的锁释放掉了，但是线程b临界区业务代码可能都还没执行完呢。

### 方案四：SET EX PX NX  + 校验唯一随机值,再删除

既然锁可能被别的线程误删，那我们给value值设置一个标记当前线程唯一的随机数，在删除的时候，校验一下，不就OK了嘛。伪代码如下：

```csharp
if（jedis.set(key_resource_id, uni_request_id, "NX", "EX", 100s) == 1）{ //加锁
    try {
        do something  //业务处理
    }catch(){
  }
  finally {
       //判断是不是当前线程加的锁,是才释放
       if (uni_request_id.equals(jedis.get(key_resource_id))) {
        jedis.del(lockKey); //释放锁
        }
    }
}
```

在这里，**「判断是不是当前线程加的锁」**和**「释放锁」**不是一个原子操作。如果调用jedis.del()释放锁的时候，可能这把锁已经不属于当前客户端，会解除他人加的锁。

<img src="https://mmbiz.qpic.cn/mmbiz_png/sMmr4XOCBzGxM0ZotibjMv7bw8KMNT5buv3sEKqlzF69a5d8OibovIwAWdNwD7O55zTMDWySkF4HpHB2vJjDIbXw/640?wx_fmt=png" alt="图片" style="zoom: 67%;" />

为了更严谨，一般也是用lua脚本代替。lua脚本如下：

```java
if redis.call('get',KEYS[1]) == ARGV[1] then 
   return redis.call('del',KEYS[1]) 
else
   return 0
end;
```



## Redis事务

### 概述

Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：

1.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。

2.服务器角度，利用setnx实现锁。

**MULTI，EXEC，DISCARD，WATCH 四个命令是 Redis 事务的四个基础命令**。其中：

MULTI，告诉 Redis 服务器开启一个事务。注意，只是开启，而不是执行 。 
EXEC，告诉 Redis 开始执行事务 。 
DISCARD，告诉 Redis 取消事务。 
WATCH，监视某一个键值对，它的作用是在事务执行之前如果监视的键值被修改，事务会被取消。

**可以利用watch实现cas乐观锁**



### Redis事务命令

| 命令                    | 说明                                                         | 备注                                                         |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| multi                   | 开启事务命令，之后的命令就进入队列，而不会马上被执行         | 在事务生存期间，所有的 Redis 关于数据结构的命令都会入队      |
| watch key1 \[key2 …\]   | 监听某些键，当被监听的键在事务执行前被修改，则事务会被回滚   | 使用乐观锁                                                   |
| unwatch key1 \[key2 …\] | 取消监听某些键                                               | –                                                            |
| exec                    | 执行事务，如果被监听的键没有被修改，则采用执行命令，否则就回滚命令 | 在执行事务队列存储的命令前， Redis 会检测被监听的键值对有没有发生变化，如果没有则执行命令 ，否则就回滚事务 |
| discard                 | 回滚事务                                                     | 回滚进入队列的事务命令，之后就不能再用 exec命令提交了        |



### 事务基本使用

**Redis 中的事务从开始到结束也是要经历三个阶段**：

*   开启事务
*   命令入列
*   执行事务/放弃事务

其中，开启事务使用 **multi命令**，事务执行使用 **exec命令**，放弃事务使用 **discard命令**。



### 开启事务

**multi 命令**用于开启事务，实现代码如下：

```redis
> multi
OK
```

multi 命令可以让客户端从非事务模式状态，变为事务模式状态。
**注意**：multi 命令不能嵌套使用，如果已经开启了事务的情况下，再执行 multi 命令，会提示如下错误：

当客户端是非事务状态时，使用 multi 命令，客户端会返回结果 OK ，如果客户端已经是事务状态，再执行 multi 命令会 multi 命令不能嵌套的错误，但不会终止客户端为事务的状态，



### 命令入列

客户端进入事务状态之后，执行的所有常规 Redis 操作命令（非触发事务执行或放弃和导致入列异常的命令）会依次入列，命令入列成功后会返回 QUEUED
**注意**：命令会按照先进先出（FIFO）的顺序出入列，也就是说事务会按照命令的入列顺序，从前往后依次执行。



### 执行事务/放弃事务

**执行事务的命令是 exec ，放弃事务的命令是 discard** 。 执行事务示例代码如下：

```
127.0.0.1:6379> multi
OK
127.0.0.1:6379> set aa bb
QUEUED
127.0.0.1:6379> exec
1) OK
127.0.0.1:6379> get aa
"bb"
127.0.0.1:6379>
```

**放弃事务示例代码如下**：

```
127.0.0.1:6379> multi
OK
127.0.0.1:6379> set cc dd
QUEUED
127.0.0.1:6379> discard
OK
127.0.0.1:6379> get cc
(nil)
127.0.0.1:6379>
```



### 事务错误&回滚

事务执行中的错误分为以下三类：

*   执行时才会出现的错误（简称：执行时错误）；
*   入列时错误，不会终止整个事务；
*   入列时错误，会终止整个事务。



#### 执行时错误

<img src="https://img-blog.csdnimg.cn/2021063011023210.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxOTYwNjIz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

从以上结果可以看出，即使事务队列中某个命令在执行期间发生了错误，事务也会继续执行，直到事务队列中所有命令执行完成。



#### 入列错误不影响事务

<img src="https://img-blog.csdnimg.cn/20210630110420344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxOTYwNjIz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />  
可以看出，重复执行 multi 会导致入列错误，但不会终止事务，最终查询的结果是事务执行成功了。除了重复执行 multi 命令，还有在事务状态下执行 watch 也是同样的效果，下文会详细讲解关于 watch 的内容。



#### 入列错误导致事务结束

<img src="https://img-blog.csdnimg.cn/2021063011072949.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxOTYwNjIz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />



### 为什么不支持事务回滚

**Redis 官方文档的解释大概的意思是，不支持事务回滚的原因有以下两个**：

*   他认为 Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能；
*   不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。

**这里不支持事务回滚，指的是不支持运行时错误的事务回滚。**



### 监控

watch 命令用于客户端并发情况下，为事务提供一个乐观锁（CAS，Check And Set），也就是可以用 watch 命令来监控一个或多个变量，如果在事务的过程中，**某个监控项被修改了，那么整个事务就会终止执行**。 watch 基本语法如下：

> watch key \[key …\]

**watch 示例代码如下**：

```
> watch k
OK
> multi
OK
> set k v2
QUEUED
> exec
(nil)
> get k
"v"
```

**注意**： watch 命令只能在客户端开启事务之前执行，在事务中执行 watch 命令会引发错误，但不会造成整个事务失败，如下代码所示：

```
> multi
OK
> set k v3
QUEUED
> watch k
(error) ERR WATCH inside MULTI is not allowed
> exec
1) OK
> get k
"v3"
```

  unwatch 命令用于清除所有之前监控的所有对象（键值对）。 unwatch 示例如下所示：

```
> set k v
OK
> watch k
OK
> multi
OK
> unwatch
QUEUED
> set k v2
QUEUED
> exec
1) OK
2) OK
> get k
"v2"
```

可以看出，即使在事务的执行过程中，k 值被修改了，因为调用了 unwatch 命令，整个事务依然会顺利执行。



## Redis是否支持ACID

**在学习数据库原理的时候有提到过事务的 ACID，即原子性、一致性、隔离性、持久性。接下来，看看 Redis 事务是否支持 ACID**。

原子性，即一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。Redis 事务不支持原子性，最明显的是 Redis 不支持回滚操作。一致性，在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这一点，Redis 事务能够保证。

隔离性，当两个或者多个事务并发访问（此处访问指查询和修改的操作）数据库的同一数据时所表现出的相互关系。Redis 不存在多个事务的问题，因为 Redis 是单进程单线程的工作模式。

持久性，在事务完成以后，该事务对数据库所作的更改便持久地保存在数据库之中，并且是完全的。Redis 提供两种持久化的方式，即 RDB 和 AOF。RDB 持久化只备份当前内存中的数据集，事务执行完毕时，其数据还在内存中，并未立即写入到磁盘，所以 RDB 持久化不能保证 Redis 事务的持久性。再来讨论 AOF 持久化，我在《深入剖析 Redis AOF 持久化策略》中讨论过：Redis AOF 有后台执行和边服务边备份两种方式。后台执行和 RDB 持久化类似，只能保存当前内存中的数据集；边备份边服务的方式中，因为 Redis 只是每间隔 2s 才进行一次备份，因此它的持久性也是不完整的！

当然，我们可以自己修改源码保证 Redis 事务的持久性，这不难。

还有一个亮点，就是 check-and-set CAS。一个修改操作不断的判断X 值是否已经被修改，直到 X 值没有被其他操作修改，才设置新的值。Redis 借助 WATCH/MULTI 命令来实现 CAS 操作的。

实际操作中，多个线程尝试修改一个全局变量，通常我们会用锁，从读取这个变量的时候就开始锁住这个资源从而阻挡其他线程的修改，修改完毕后才释放锁，这是悲观锁的做法。相对应的有一种乐观锁，乐观锁假定其他用户企图修改你正在修改的对象的概率很小，直到提交变更的时候才加锁，读取和修改的情况都不加锁。一般情况下，不同客户端会访问修改不同的键值对，因此一般 check 一次就可以 set 了，而不需要重复 check 多次。



## Redis缓存与数据库同步

1. 先更新数据库，再更新缓存带来的问题：

   - 两个请求A,B同时更改数据库，A先改完，B后改完，但是B先去修改的缓存，之后A再去修改缓存，这样就导致缓存的是A修改的数据，不是B修改的数据。
   - 两个请求A,B。A请求先更改数据库，还没等修改缓存。B请求先放问到缓存，然后读取了旧数据。

2. 先更新缓存，再更新数据库带来的问题：

   - 和上一个第一条一样
   - 先更新缓存，异步更新数据库会导致数据的丢失，如果持久化做的不好的话。

3. 先删除缓存，后更新数据库带来的问题

   - 请求A先删除缓存，这时候请求B查看缓存，发现没有，先去查询数据库，然后更新缓存，这个时候请求A的更新数据库操作才到。导致缓存里又拿到了旧数据。在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题。



**解决方案：先更新数据库，再删除缓存**

   **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
   **命中**：应用程序从cache中取数据，取到后返回。
   **更新**：先把数据存到数据库中，成功后，再让缓存失效。

先更新数据库，再删除缓存也是会出现数据不一致性的问题，

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZed1sKhdbWWdHmnetCfhPiaSbCpD93HnyVTmDnibia5draqMTpRKfsSRndjcf1iaDK2wqqKYnFwwVCanw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

**但是在实际中，这个问题出现的概率并不高。因为缓存的写入通常要远远快于数据库的写入**，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。

   所以从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。



**还有个问题**

如果缓存删除失败的话，那就会频繁访问旧的数据。



**该怎么解决呢？**

有两种方法：重试机制和订阅 `MySQL binlog`，再操作缓存



重试机制

<img src="https://img-blog.csdnimg.cn/20200115174505427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDQ5MzA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

`MySQL binlog`

「**先更新数据库，再删缓存**」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 `binlog` 里。于是我们就可以通过订阅 `binlog` 日志，拿到具体要操作的数据，然后再执行缓存删除。

<img src="https://img-blog.csdnimg.cn/20200115174533970.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDQ5MzA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />
